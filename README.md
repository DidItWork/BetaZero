# SigmaZero
An implementation of Reinforcement Learning in game-playing according to Alpha Zero

## Logic

### Game Tree Node Attributes
- $N_i$, number of times node has been selected / number of times the node has been through the simulation (integer)
- $W_i$, the sum of expected value of the node (not an integer, "the number of wins for the node")
- $p$, policy values of child nodes
- $s$, representation of board state (8x8xN tensor)

### Alpha Zero MCTS
1. Selection: Start from root node (current game state) and select successive nodes based on Upper Confidence Bound Criterion (UCB) until a leaf node L is reached (a leaf node is any node that has a potential child from which no simulation has yet been initiated) or a terminal node.
$$\text{UCB} = \frac{W_i}{N_i}+p_ic\frac{\sqrt{N_i}}{1+n_i}$$
, where $c$ is a constant, $p_i$ is the policy of the child node and $n_i$ is its simulation count
3. Expansion: Unless L ends the game decisively for either player, randomly initialize an unexplored child node.
4. Backpropagation: Using the value generated by the neural network $f_\theta$, update the N and W values of the current node and all its parent nodes.
5. Repeat steps 1 to 3 for N iterations

### Self-Play and Training
1. Self-Play until the game ends using MCTS and $f_\theta$
2. Store the chosen action taken at each state and the values of the node (-1,0,1) depending on the player and whether he won or lost the game. One training sample should contain: (board state s, the action chosen $\pi$, the value of the node z)
3. Minimize loss function of the training samples in the batch.
$$l = (z-v)^2-\pi^T\log{p}+c||\theta||^2$$, $c$ is a constant

### Board State Representation

TODO

### Action Representation

The actions are represented with an 8x8x73 tensor which can be flattened into a 4672 vector. The planes of the tensor represent the location on the board from which the chess piece should be picked up from.

- The first 8x7 channels/planes represent the number of squares to move (1 to 7) for the queen/rook/pawn/bishop/king as well as the direction. (Movement of pawn from 7th rank is assumed to be a promotion to queen)
- The next 8 channels/planes represent the direction to move the knight
- The last 9 channels represent the underpromotion of the pawn to knight, bishop, and rook resp. (through moving one step from the 7th rank or a diagonal capture from the 7th rank).